[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "Hi! I’m Akshay, a PhD student at QuantumGroup@UGent with an interest in the exotic physics of Bose-Einstein condensates and programming. I am currently working on utilizing Tensor Network techniques to study BEC systems in the context of quantum simulation experiments. When I’m not performing research, I enjoy making games with the Godot engine. You can find out more about the things I work on in my main website.\nOver the past year, I’ve found that my research seems to involve solving many tiny problems which have some insight to offer but not enough to share in any usual platforms of scientific discourse. As an attempt to preserve these tidbits from fading into obscurity as I inevitably forget about them, I have begun documenting them here."
  },
  {
    "objectID": "posts/indexing-scheme/index.html",
    "href": "posts/indexing-scheme/index.html",
    "title": "Linearly indexing a 2D grid",
    "section": "",
    "text": "Recently, I had to write an exact diagonalization routine to solve for the ground state of a system of interacting bosons in the continuum. Generally this simply involves choosing a single-particle basis set, \\(\\{\\phi_i(\\vec{r})\\}|_{i=1}^N\\) such that a many-particle basis set may be constructed by enumerating the Fock states, \\(\\{\\ket{n_1, n_2, \\dots, n_N}\\}\\) respecting the bosonic/fermionic symmetry. These states can then be utilized to explicitly construct the Hamiltonian by computing its matrix elements.\nWe see then that the core subroutine is agnostic to the physical dimensionality of the problem as this information is already abstracted out at the level of the Fock states. In such a case, extending a code developed with 1D systems in mind to higher dimensions is as simple as finding a consistent linear indexing scheme for the single-particle basis set in order to construct the basis of Fock states.\nIn my particular case, I was working with a 1D system under the influence of a harmonic potential, so the Hermite modes, \\(\\{h_n(x)\\}\\) where \\(n \\in \\mathbb{N}\\) with single-particle energies \\(\\epsilon(n) = \\hbar \\omega (n + 1/2)\\), served as a natural single-particle basis. Upon requiring an extension to 2D, a natural choice for the basis can be constructed as a product of the 1D modes, \\(\\{h_{n_x}(x)h_{n_y}(y)\\}\\) where \\(n_x, n_y \\in \\mathbb{N}\\) with single-particle energies \\(\\epsilon(n_x, n_y) = \\hbar \\omega (n_x + n_y + 1)\\). We thus require a mapping scheme \\(\\mathbb{N} \\times \\mathbb{N} \\to \\mathbb{N}\\) in order to linearly index this basis set."
  },
  {
    "objectID": "posts/indexing-scheme/index.html#constructing-the-indexing-scheme",
    "href": "posts/indexing-scheme/index.html#constructing-the-indexing-scheme",
    "title": "Linearly indexing a 2D grid",
    "section": "Constructing the indexing scheme",
    "text": "Constructing the indexing scheme\nThe modes are labelled by two numbers \\((n_x, n_y)\\), both of which are non-negative integers. A natural ordering scheme presents itself in the form of increasing energy eigenvalues, however the spectrum is fairly degenerate since \\(\\epsilon(n_x, n_y) = \\hbar \\omega (n_x + n_y + 1)\\). This degeneracy actually lets us come up with a scheme quite easily.\n\n\n\n\n\nWe can break down the scheme into two pieces; (1) identify the degeneracy level, (2) identify the location within the level. We know that a mode \\((n_x, n_y)\\) must belong to a level with degeneracy \\(n_x + n_y + 1\\). This means that the number of elements in the lower energy levels is given by:\n\\[\\begin{equation} \\sum_{n = 1}^{n_x + n_y} n  = \\frac{(n_x + n_y)(n_x + n_y + 1)}{2} \\end{equation}\\]\nWithin the level, \\(n_y\\) itself provides a natural way of ordering the modes. We can thus write a linear indexing scheme like so:\n\\[\\begin{equation} n = \\frac{(n_x + n_y)(n_x + n_y + 1)}{2}  + n_y \\end{equation}\\]\nOf course, we could equivalently use \\(n_x\\) instead.\nAlthough it is not readily apparent due to the quadratic nature of this mapping, we expect that it is invertible by construction. In such a case, we have effectively constructed a bijection from the natural numbers to a pair of natural numbers. In fact, what we have here is Cantor’s pairing function, which is the only bijective quadratic function on \\(\\mathbb{N} \\times \\mathbb{N} \\to \\mathbb{N}\\). The existence of this function shows that 2-tuples of natural numbers are countable! By extension, we can easily show that the set of rational numbers are countable as well.\nWhile its not too surprising that this result is well-known and has ties to number theory, I found it really nice that it naturally popped up as a practical solution to a seemingly unrelated logistical problem involving the numerical implementation of exact diagonalization."
  },
  {
    "objectID": "posts/signal-crop/index.html",
    "href": "posts/signal-crop/index.html",
    "title": "Automating image cropping",
    "section": "",
    "text": "Sometimes being a (numerical) theorist gets a bit tiring. In those moments, I occasionally peak into what my colleagues are working on with the BEC experiment downstairs. If they happen to be facing an interesting logistical problem, its quite fun to see if it can be automated with code. One such problem popped up early on in the calibration phase of the experiment; namely, we had to profile a certain gaussian laser beam belonging to the AOD system to see if it was tuned correctly. Typically, this involved capturing 2D images of the intensity profile like so:\nActivating project at `~/Documents/PhDstuff/ResearchTidbits`\nbegin\n    data = load(\"signal.jld2\")[\"images\"]\n    plot(heatmap(data[1], title=\"Image #1\"), heatmap(data[2], title=\"Image #2\"), size=(1000, 300))\nend\nThese images have quite a high resolution but the actual signal is tiny and most of the space is just empty. So, before running any analysis routines on this data, it must be cropped to put the actual beam in focus. Nowadays this can be easily achieved with the host of computer vision algorithms that can be found in mature ecosystems such as OpenCV. However, I wanted to see if a simpler approach was possible here since the signal is not particularly complex in its structure. In the ideal case, it is supposed to be an exact gaussian beam, although in this particular instance, there was some odd modulation of interference fringes within the spot which is what we wanted to investigate."
  },
  {
    "objectID": "posts/signal-crop/index.html#automating-the-cropping",
    "href": "posts/signal-crop/index.html#automating-the-cropping",
    "title": "Automating image cropping",
    "section": "Automating the cropping",
    "text": "Automating the cropping\nI have not spent too much time to figure out exactly why the solution works, so I simply outline the procedure here and discuss how we stumbled upon it. I should note here that what follows was largely borne out of discussions with Dhruva Sambrani.\nBefore proceeding, we assume that there is only a single point of interest and it is roughly a single-peaked intensity distribution. Finding the point of interest (i.e., the signal peak) is usually not too hard since one may use boxed-averages or some other sophisticated algorithm (there is an excellent stack exchange thread on this) to locate regions of interest where the intensity peaks. Obtaining a measure of the spread of the spot is a bit harder though. Ideally the signal is equipped with a standard deviation as it is a gaussian beam, but we cannot perform a linear regression to fit it to this model and extract the parameter as such (the whole point is to reduce the size of the image before doing these things). One may also just compute \\(\\sigma = \\sqrt{\\int x^2 \\cdot I(x) dx - (\\int x \\cdot I(x) dx)^2}\\) using the discrete data, \\(I(x_i)\\) with \\(x_i\\) being the pixel co-ordinates. But in higher dimensions, this would require performing independant calculations across multiple cross-sections (either horizontal/vertical or radially outwards) and averaging those out, but we are lazy programmers trying to find the path of least action. So we instead look for some simpler qualitative measure that approximately gives us the spread.\nThe rough idea is as follows; we expect that the standard deviation of the intensity values around the peak of the beam should hold the information of the signal spread (there is likely a direct relation here). This is simple to compute; \\(stddev(I) = \\frac{1}{N} \\sum_{i} (I_i - \\bar{I})^2\\) where \\(\\bar{I}\\) is the mean intensity within the area. However, we do not know how large an area around the peak must be considered to compute this deviation.\nIn order to facilitate the exploration of this concept, we first write a small function to extract the indices corresponding to a (hyper-cube) of length 2 * window centered around the point anchor. All the code in this post is written to be applicable regardless of the dimensionality of the data.\n\nfunction cube(anchor, window)\n    return [\n        rmin:rmax for (rmin, rmax) in\n        zip(anchor .- window, anchor .+ window)\n    ]\nend\n\ncube (generic function with 1 method)\n\n\nWe then define the measure of the extent of the signal as the standard deviation of the intensity values in a cube of pixels centered around the signal peak.\n\nmeasure_extent(data, anchor, window) = std(data[cube(anchor, window)...])\n\nmeasure_extent (generic function with 1 method)\n\n\nThe qualitative value of the signal spread is determined by computing the above measure over a range of (hyper-)cube sizes around the signal peak, and finding the point where it is maximum. Since this is only a qualitative value, we still require a hand-tuned parameter scale to adjust the final result.\n\n# extract (hyper-)cubical ranges for cropping; f - measure of extent\nfunction crop_extents(data; scale=5, max_window=200, f=measure_extent)\n    anchor = Tuple(argmax(data)) # replace with robust peak finding algorithm   \n    extent = argmax([f(data, anchor, window) for window in 1:max_window])\n\n    return cube(anchor, extent * scale)\nend\n\ncrop_extents (generic function with 1 method)\n\n\nThe biggest assumption here is that the standard deviation curve peaks at some non-zero value of the window size. We see that this is indeed the case for a unimodal distribution using some generated 1D data.\n\nlet\n    gaussian1D(x, A, x0, sig) = A * exp(-(x - x0)^2 / (2 * sig^2))\n    x = -50:0.1:50\n    y = gaussian1D.(x, 1, 20, 1)\n    yerr = 0.5 * rand(length(x))\n\n    anchor, anchorerr = argmax(y), argmax(y .+ yerr)\n    windows = 1:170\n    rng = [measure_extent(y, anchor, window) for window in windows]\n    rngerr = [measure_extent(y .+ yerr, anchor, window) for window in windows]\n\n    plot(windows, rng, lab=\"Clean signal\", lw=2, c=1)\n    plot!(windows, rngerr, lab=\"Noisy signal\", lw=2, c=2)\n    vline!([argmax(rng)], c=1, lab=\"\", ls=:dash, alpha=0.75)\n    vline!([argmax(rngerr)], c=2, lab=\"\", ls=:dash, alpha=0.75)\n\n    plot!(legend=:bottomright, xlabel=\"Independant variable\", ylabel=\"Measure of signal spread\")\nend\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe boxed standard deviation measure seems to monotonically increase upto a maximum value and then continues to monotonically decrease. The window size which achieves the maximum value of this measure gives us a qualitative correspondence to the extent of the signal. We simply extract this value and use an appropriate multiplier to crop the data as required.\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome caveats with this method seems to be that:\n\nhigh sensitivity to estimated location of the peak of the signal, i.e, the anchor.\nthe signal must have minimal overlap with other signals, and roughly symmetric spread (i.e., gaussian-like, without long tails) to ensure optimal performance.\n\nFor what came out of a quick text conversation with a friend, this was a pretty interesting find!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ResearchTidbits",
    "section": "",
    "text": "Automating image cropping\n\n\n\ntidbit\n\ncode\n\nbec\n\n\n\n\n\n\n\n\n\nMay 4, 2025\n\n\nAkshay Shankar, Dhruva Sambrani\n\n\n\n\n\n\n\n\n\n\n\n\nLinearly indexing a 2D grid\n\n\n\ntidbit\n\nnumber theory\n\n\n\n\n\n\n\n\n\nMay 1, 2025\n\n\nAkshay Shankar\n\n\n\n\n\nNo matching items"
  }
]